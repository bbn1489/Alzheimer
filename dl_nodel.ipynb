{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9891e9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports done!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 1: IMPORTS\n",
    "# ============================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "print(\"‚úÖ Imports done!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ed93f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ FOLDER STRUCTURE:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#second cell: FOLDER STRUCTURE\n",
    "# ============================================\n",
    "base_path = 'C:\\\\Users\\\\bbnro\\\\Downloads\\\\archive\\\\AugmentedAlzheimerDataset'\n",
    "\n",
    "print(\"üìÅ FOLDER STRUCTURE:\\n\")\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    level = root.replace(base_path, '').count(os.sep)\n",
    "    indent = '  ' * level\n",
    "    print(f\"{indent}üìÇ {os.path.basename(root)}/\")\n",
    "    if level < 2:  # Don't go too deep\n",
    "        for d in dirs:\n",
    "            print(f\"{indent}  üìÅ {d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53978859",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\bbnro\\\\Downloads\\\\archive\\\\AugmentedAlzheimerDataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1075866942.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mclass_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\bbnro\\\\Downloads\\\\archive\\\\AugmentedAlzheimerDataset'"
     ]
    }
   ],
   "source": [
    "#third cell: image counts per class\n",
    "# ============================================\n",
    "augmented_path = 'C:\\\\Users\\\\bbnro\\\\Downloads\\\\archive\\\\AugmentedAlzheimerDataset'\n",
    "\n",
    "class_counts = {}\n",
    "for class_name in os.listdir(augmented_path):\n",
    "    class_path = os.path.join(augmented_path, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        count = len(os.listdir(class_path))\n",
    "        class_counts[class_name] = count\n",
    "\n",
    "# Display as DataFrame\n",
    "df_counts = pd.DataFrame({\n",
    "    'Class': list(class_counts.keys()),\n",
    "    'Count': list(class_counts.values())\n",
    "})\n",
    "df_counts = df_counts.sort_values('Count', ascending=False)\n",
    "print(df_counts.to_string(index=False))\n",
    "print(f\"\\nüìä Total Images: {sum(class_counts.values())}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf2e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4: PLOT CLASS DISTRIBUTION\n",
    "# ============================================\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n",
    "bars = plt.bar(class_counts.keys(), class_counts.values(), color=colors)\n",
    "plt.title('üß† Alzheimer MRI Dataset - Class Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Dementia Stage')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(rotation=15)\n",
    "\n",
    "# Add count labels on bars\n",
    "for bar, count in zip(bars, class_counts.values()):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 100, \n",
    "             str(count), ha='center', fontweight='bold')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check if balanced\n",
    "print(\"\\nüîç CLASS BALANCE CHECK:\")\n",
    "max_count = max(class_counts.values())\n",
    "min_count = min(class_counts.values())\n",
    "print(f\"   Max: {max_count}, Min: {min_count}\")\n",
    "print(f\"   Ratio: {max_count/min_count:.2f}x difference\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e2f9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 5: VIEW SAMPLE IMAGES FROM EACH CLASS\n",
    "# ============================================\n",
    "augmented_path = 'C:\\\\Users\\\\bbnro\\\\Downloads\\\\archive\\\\AugmentedAlzheimerDataset'\n",
    "\n",
    "fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
    "class_names = ['NonDemented', 'VeryMildDemented', 'MildDemented', 'ModerateDemented']\n",
    "\n",
    "for row, class_name in enumerate(class_names):\n",
    "    class_path = os.path.join(augmented_path, class_name)\n",
    "    images = os.listdir(class_path)[:5]  # Get first 5 images\n",
    "    \n",
    "    for col, img_name in enumerate(images):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        img = Image.open(img_path)\n",
    "        axes[row, col].imshow(img, cmap='gray')\n",
    "        axes[row, col].axis('off')\n",
    "        if col == 0:\n",
    "            axes[row, col].set_title(f'{class_name}', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('üß† MRI Samples: Progression of Alzheimer\\'s Disease', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce14b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 6: CHECK IMAGE DIMENSIONS & PROPERTIES\n",
    "# ============================================\n",
    "augmented_path = 'C:\\\\Users\\\\bbnro\\\\Downloads\\\\archive\\\\AugmentedAlzheimerDataset'\n",
    "\n",
    "# Sample random images to check dimensions\n",
    "sample_dims = []\n",
    "sample_modes = []\n",
    "\n",
    "for class_name in os.listdir(augmented_path):\n",
    "    class_path = os.path.join(augmented_path, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        images = os.listdir(class_path)[:50]  # Check 50 from each class\n",
    "        for img_name in images:\n",
    "            img = Image.open(os.path.join(class_path, img_name))\n",
    "            sample_dims.append(img.size)\n",
    "            sample_modes.append(img.mode)\n",
    "# Analyze dimensions\n",
    "unique_dims = Counter(sample_dims)\n",
    "unique_modes = Counter(sample_modes)\n",
    "\n",
    "print(\"üìê IMAGE DIMENSIONS:\")\n",
    "for dim, count in unique_dims.most_common():\n",
    "    print(f\"   {dim[0]} x {dim[1]} pixels: {count} images\")\n",
    "\n",
    "print(f\"\\nüé® COLOR MODES:\")\n",
    "for mode, count in unique_modes.items():\n",
    "    mode_desc = {'L': 'Grayscale', 'RGB': 'Color', 'RGBA': 'Color+Alpha'}\n",
    "    print(f\"   {mode_desc.get(mode, mode)}: {count} images\")\n",
    "# Get one sample for detailed info\n",
    "sample_img = Image.open(os.path.join(augmented_path, 'NonDemented', os.listdir(os.path.join(augmented_path, 'NonDemented'))[0]))\n",
    "print(f\"\\nüìã SAMPLE IMAGE INFO:\")\n",
    "print(f\"   Size: {sample_img.size}\")\n",
    "print(f\"   Mode: {sample_img.mode}\")\n",
    "print(f\"   Format: {sample_img.format}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf82e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 7: MARKDOWN - DATA ANALYSIS SUMMARY\n",
    "# ============================================\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "summary = \"\"\"\n",
    "## üìã Data Analysis Summary\n",
    "\n",
    "### Dataset Overview\n",
    "- **Total Images:** 33,984\n",
    "- **Classes:** 4 (NonDemented, VeryMildDemented, MildDemented, ModerateDemented)\n",
    "- **Class Balance:** 1.49x ratio (acceptable)\n",
    "\n",
    "### Image Properties\n",
    "- **Sizes:** Mixed (200√ó190 and 180√ó180) ‚Üí Need resizing\n",
    "- **Format:** JPEG, RGB color mode\n",
    "- **Quality:** Good, augmentation already applied\n",
    "### Medical Insight\n",
    "- Alzheimer's causes **brain atrophy** (shrinkage)\n",
    "- **Ventricles enlarge** as disease progresses\n",
    "- Model should learn to detect these structural changes\n",
    "\n",
    "### Preprocessing Decisions\n",
    "1. ‚úÖ Resize all images to **176√ó176** (balanced size)\n",
    "2. ‚úÖ Keep RGB or convert to grayscale\n",
    "3. ‚úÖ Normalize pixel values to [0,1]\n",
    "4. ‚úÖ Use Original dataset for validation (no data leakage)\n",
    "\"\"\"\n",
    "display(Markdown(summary))\n",
    "\n",
    "# Clear any cached imports\n",
    "import sys\n",
    "if 'google.protobuf' in sys.modules:\n",
    "    del sys.modules['google.protobuf']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a4e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#note this cell is slightly difrent from the chromebook version\n",
    "# CELL 8: BUILD DATA GENERATORS\n",
    "# ============================================\n",
    "# CELL 8: BUILD DATA GENERATORS\n",
    "# ============================================\n",
    "train_path = 'C:\\\\Users\\\\bbnro\\\\Downloads\\\\archive\\\\AugmentedAlzheimerDataset'\n",
    "test_path = 'C:\\\\Users\\\\bbnro\\\\Downloads\\\\archive\\\\OriginalDataset'\n",
    "\n",
    "# Image parameters\n",
    "IMG_SIZE = (176, 176)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Load training data\n",
    "train_generator = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_path,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical',\n",
    "    validation_split=0.15,\n",
    "    subset='training',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Store class names before mapping\n",
    "class_names = sorted(os.listdir(train_path))\n",
    "\n",
    "# Load validation data\n",
    "val_generator = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_path,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical',\n",
    "    validation_split=0.15,\n",
    "    subset='validation',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Load test data\n",
    "test_generator = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_path,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "# Normalize pixel values\n",
    "normalize = tf.keras.layers.Rescaling(1./255)\n",
    "train_generator = train_generator.map(lambda x, y: (normalize(x), y))\n",
    "val_generator = val_generator.map(lambda x, y: (normalize(x), y))\n",
    "test_generator = test_generator.map(lambda x, y: (normalize(x), y))\n",
    "\n",
    "print(\"\\n‚úÖ Data Generators Ready!\")\n",
    "print(f\"   Training samples: {tf.data.experimental.cardinality(train_generator).numpy() * BATCH_SIZE}\")\n",
    "print(f\"   Validation samples: {tf.data.experimental.cardinality(val_generator).numpy() * BATCH_SIZE}\")\n",
    "print(f\"   Test samples: {tf.data.experimental.cardinality(test_generator).numpy() * BATCH_SIZE}\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# ============================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118ff852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 9: VISUALIZE A BATCH\n",
    "# ============================================\n",
    "# Get one batch to verify\n",
    "images, labels = next(iter(train_generator))\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Ensure image is in correct format for display\n",
    "    img_display = (images[i].numpy() * 255).astype(np.uint8)\n",
    "    ax.imshow(img_display, cmap='gray')\n",
    "    label_idx = np.argmax(labels[i])\n",
    "    ax.set_title(f'{class_names[label_idx]}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Sample Batch from Training Generator', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Batch shape: {images.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "print(f\"Pixel range: [{images.numpy().min():.3f}, {images.numpy().max():.3f}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f6910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 10: FIX PROTOBUF (Run this first!)\n",
    "# ============================================\n",
    "#!pip uninstall -y protobuf\n",
    "#!pip install protobuf==3.20.3 --quiet\n",
    "\n",
    "print(\"‚úÖ Protobuf fixed! Now restart kernel:\")\n",
    "print(\"   Session ‚Üí Restart Session\")\n",
    "print(\"   Then re-run all cells before continuing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34629c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 11: IMPORTS & GPU CHECK\n",
    "# ============================================\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB3, ResNet50V2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Check GPU\n",
    "print(\"üî• GPU Status:\")\n",
    "print(f\"   TensorFlow version: {tf.__version__}\")\n",
    "print(f\"   GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(f\"   Built with CUDA: {tf.test.is_built_with_cuda()}\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"\\n‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0744fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 12: ENHANCED DATA GENERATORS\n",
    "# ============================================\n",
    "\n",
    "# Paths\n",
    "\n",
    "train_path = 'C:\\\\Users\\\\bbnro\\\\Downloads\\\\archive\\\\AugmentedAlzheimerDataset'\n",
    "test_path = 'C:\\\\Users\\\\bbnro\\\\Downloads\\\\archive\\\\OriginalDataset'\n",
    "# Image parameters\n",
    "IMG_SIZE = (224, 224)  # EfficientNet/ResNet optimal size\n",
    "BATCH_SIZE = 16  # Smaller batch for better generalization\n",
    "\n",
    "# Training generator - MINIMAL augmentation (data already augmented!)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,  # Slight rotation only\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    validation_split=0.2  # 20% for validation\n",
    ")\n",
    "\n",
    "# Test generator - NO augmentation\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_gen = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Calculate class weights to handle imbalance\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(train_gen.classes),\n",
    "    y=train_gen.classes\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"\\n‚úÖ Data Generators Created!\")\n",
    "print(f\"   Training samples: {train_gen.samples}\")\n",
    "print(f\"   Validation samples: {val_gen.samples}\")\n",
    "print(f\"   Test samples: {test_gen.samples}\")\n",
    "print(f\"\\nüìö Class Mapping: {train_gen.class_indices}\")\n",
    "print(f\"\\n‚öñÔ∏è Class Weights: {class_weights_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783c2690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 13: VERIFY DATA PIPELINE\n",
    "# ============================================\n",
    "\n",
    "images, labels = next(train_gen)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 7))\n",
    "class_names = list(train_gen.class_indices.keys())\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(images[i])\n",
    "    label_idx = np.argmax(labels[i])\n",
    "    ax.set_title(f'{class_names[label_idx]}', fontsize=11, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('‚úÖ Sample Training Batch (After Preprocessing)', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Batch Info:\")\n",
    "print(f\"   Shape: {images.shape}\")\n",
    "print(f\"   Pixel range: [{images.min():.3f}, {images.max():.3f}]\")\n",
    "print(f\"   Data type: {images.dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663985fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 14: BUILD CUSTOM CNN (NO DOWNLOADS!)\n",
    "# ============================================\n",
    "\n",
    "def build_custom_cnn():\n",
    "    \"\"\"\n",
    "    Custom CNN optimized for MRI brain scans\n",
    "    Designed to hit 98%+ accuracy\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # Block 1\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        # Block 2\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        # Block 3\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        # Block 4\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Block 5 (Deeper)\n",
    "        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        # Dense layers\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        # Output layer\n",
    "        layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_custom_cnn()\n",
    "\n",
    "# Compile with Adam optimizer\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "print(\"‚úÖ Custom CNN Built!\")\n",
    "print(f\"\\nüìä Total Parameters: {model.count_params():,}\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bd02e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 15: CALLBACKS (SAME AS BEFORE)\n",
    "# ============================================\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=7,  # Increased patience for custom CNN\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=4,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_alzheimer_model.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [early_stop, reduce_lr, checkpoint]\n",
    "print(\"‚úÖ Callbacks ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd136f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CELL 16: TRAIN THE MODEL\n",
    "# # ============================================\n",
    "\n",
    "# print(\"üöÄ Starting training...\")\n",
    "# print(f\"‚ö†Ô∏è GPU Status: {'ENABLED ‚úÖ' if tf.config.list_physical_devices('GPU') else 'DISABLED - Training will be slow ‚ö†Ô∏è'}\")\n",
    "\n",
    "# history = model.fit(\n",
    "#     train_gen,\n",
    "#     validation_data=val_gen,\n",
    "#     epochs=30,  # Will stop early if needed\n",
    "#     class_weight=class_weights_dict,\n",
    "#     callbacks=callbacks,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# print(\"\\n‚úÖ Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4d1106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
